{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idp = ['lh_G&S_frontomargin_thickness']\n",
    "df_te  = pd.DataFrame(columns = ['age','sex', 'site', 'sitenum'], index = ['C1', 'C2', 'C3'])\n",
    "y_te = np.array([0.065884, 1.897501,1.897501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te['age'].iloc[0] = 39\n",
    "df_te['age'].iloc[1] = 30\n",
    "df_te['age'].iloc[2] = 39\n",
    "\n",
    "df_te['sex'].iloc[0] = 1\n",
    "df_te['sex'].iloc[1] = 1\n",
    "df_te['sex'].iloc[2] = 1\n",
    "\n",
    "df_te['sitenum'].iloc[0] = 1000\n",
    "df_te['sitenum'].iloc[1] = 1000\n",
    "df_te['sitenum'].iloc[2] = 1000\n",
    "\n",
    "df_te['site'].iloc[0] = 'NUDZ'\n",
    "df_te['site'].iloc[1] = 'NUDZ'\n",
    "df_te['site'].iloc[2] = 'NUDZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = ('/home/barbora/Documents/Projects/Normative_Models/ESO/models/pokus')\n",
    "os.chdir(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which data columns do we wish to use as covariates? \n",
    "cols_cov = ['age','sex']\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = -5 \n",
    "xmax = 110\n",
    "\n",
    "# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)\n",
    "outlier_thresh = 7\n",
    "\n",
    "# extract and save the response variables for the test set\n",
    "#y_te = df_te[idp].to_numpy()\n",
    "\n",
    "# save the variables\n",
    "resp_file_te = os.path.join(models_dir, 'resp_te.txt') \n",
    "np.savetxt(resp_file_te, y_te)\n",
    "    \n",
    "# configure and save the design matrix\n",
    "cov_file_te = os.path.join(models_dir, 'cov_bspline_te.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = create_design_matrix(df_te[cols_cov], \n",
    "                            site_ids = df_te['site'],\n",
    "                            all_sites = site_ids_tr,\n",
    "                            basis = 'bspline', \n",
    "                            xmin = xmin, \n",
    "                            xmax = xmax)\n",
    "np.savetxt(cov_file_te, X_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad['sitenum'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the covariates for the adaptation data\n",
    "X_ad = create_design_matrix(df_ad[cols_cov], \n",
    "                            site_ids = df_ad['site'],\n",
    "                            all_sites = site_ids_tr,\n",
    "                            basis = 'bspline', \n",
    "                            xmin = xmin, \n",
    "                            xmax = xmax)\n",
    "cov_file_ad = os.path.join(models_dir, 'cov_bspline_ad.txt')          \n",
    "np.savetxt(cov_file_ad, X_ad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the responses for the adaptation data\n",
    "resp_file_ad = os.path.join(models_dir, 'resp_ad.txt') \n",
    "y_ad = df_ad[idp].to_numpy()\n",
    "np.savetxt(resp_file_ad, y_ad)\n",
    "\n",
    "# save the site ids for the adaptation data\n",
    "sitenum_file_ad = os.path.join(models_dir, 'sitenum_ad.txt') \n",
    "site_num_ad = df_ad['sitenum'].to_numpy(dtype=int)\n",
    "np.savetxt(sitenum_file_ad, site_num_ad)\n",
    "\n",
    "# save the site ids for the test data \n",
    "sitenum_file_te = os.path.join(models_dir, 'sitenum_te.txt')\n",
    "site_num_te = df_te['sitenum'].to_numpy(dtype=int)\n",
    "np.savetxt(sitenum_file_te, site_num_te)\n",
    "\n",
    "# adaptation files are among inputs to adjust the offset \n",
    "yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                            alg = 'blr', \n",
    "                            respfile = resp_file_te, \n",
    "                            model_path = os.path.join(idp_dir,'Models'),\n",
    "                            adaptrespfile = resp_file_ad,\n",
    "                            adaptcovfile = cov_file_ad,\n",
    "                            adaptvargroupfile = sitenum_file_ad,\n",
    "                            testvargroupfile = sitenum_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idp_dir = os.path.join('/home/barbora/Documents/Projects/Normative_Models/ESO/braincharts/models/lifespan_57K_82sites',idp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create dummy data\n",
    "###\n",
    "\n",
    "# which sex do we want to plot? \n",
    "sex = 1 # 1 = male 0 = female\n",
    "if sex == 1: \n",
    "    clr = 'blue'\n",
    "else:\n",
    "    clr = 'red'\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = -5 \n",
    "xmax = 110\n",
    "\n",
    "# create dummy data for visualisation\n",
    "print('configuring dummy data ...')\n",
    "xx = np.arange(xmin, xmax, 0.5)\n",
    "X0_dummy = np.zeros((len(xx), 2))\n",
    "X0_dummy[:,0] = xx # intercept\n",
    "X0_dummy[:,1] = sex # sex covariate\n",
    "\n",
    "# create the design matrix\n",
    "X_dummy = create_design_matrix(X0_dummy, xmin=xmin, xmax=xmax, site_ids=None, all_sites=site_ids_tr)\n",
    "\n",
    "# save the dummy covariates\n",
    "cov_file_dummy = os.path.join(models_dir,'cov_bspline_dummy_mean.txt')\n",
    "np.savetxt(cov_file_dummy, X_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Plotting normative models\n",
    "###\n",
    "idp = ['lh_G&S_frontomargin_thickness']\n",
    "idp = idp[0]\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print('Running IDP',  idp, ':')\n",
    "idp_dir = os.path.join(pretrained_dir,'models','lifespan_57K_82sites', idp)\n",
    "idp_cv_dir = os.path.join(models_dir,idp)\n",
    "\n",
    "\n",
    "# load the true data points V1\n",
    "v1_yhat_te = yhat_te\n",
    "v1_s2_te = s2_te\n",
    "v1_y_te = y\n",
    "v1_bspline = pd.DataFrame(load_2d('cov_bspline_te.txt'))\n",
    "\n",
    "#########################################################################\n",
    "# set up the covariates for the dummy data\n",
    "print('Making predictions with dummy covariates (for visualisation)')\n",
    "yhat, s2 = predict(cov_file_dummy, \n",
    "                    alg = 'blr', \n",
    "                    respfile = None, \n",
    "                    model_path = os.path.join(idp_dir,'Models'), \n",
    "                    outputsuffix = '_dummy')\n",
    "\n",
    "# load the normative model\n",
    "with open(os.path.join(idp_dir,'Models', 'NM_0_0_estimate.pkl'), 'rb') as handle:\n",
    "    nm = pickle.load(handle) \n",
    "\n",
    "# get the warp and warp parameters\n",
    "W = nm.blr.warp\n",
    "warp_param = nm.blr.hyp[1:nm.blr.warp.get_n_params()+1] \n",
    "\n",
    "# warp dummy predictions to create the plots\n",
    "med, pr_int = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param)\n",
    "\n",
    "# extract the different variance components to visualise\n",
    "beta, junk1, junk2 = nm.blr._parse_hyps(nm.blr.hyp, X_dummy)\n",
    "s2n = 1/beta # variation (aleatoric uncertainty)\n",
    "s2s = s2-s2n # modelling uncertainty (epistemic uncertainty)\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#  warp predictions for the true data and compute evaluation metrics\n",
    "v1_med_te = W.warp_predictions(np.squeeze(v1_yhat_te), np.squeeze(v1_s2_te), warp_param)[0]\n",
    "v1_med_te = v1_med_te[:, np.newaxis]\n",
    "\n",
    "#print('metrics:', evaluate(y_te, med_te))\n",
    "\n",
    "\n",
    "###\n",
    "# Adjusting         \n",
    "# adjust the data based on the adaptation dataset \n",
    "###\n",
    "#  \n",
    "# load the adaptation data\n",
    "y_ad = load_2d(os.path.join(models_dir, 'resp_ad.txt'))\n",
    "X_ad = load_2d(os.path.join(models_dir, 'cov_bspline_ad.txt'))\n",
    "\n",
    "# adjust and rescale the data\n",
    "y_te_rescaled, s2_rescaled = nm.blr.predict_and_adjust(nm.blr.hyp, \n",
    "                                                        X_ad,  \n",
    "                                                        np.squeeze(y_ad), \n",
    "                                                        Xs=None, \n",
    "                                                        ys=y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save transformed predictions so that we don't have to sompute this ever again\n",
    "v1_y_te_rescaled_f = os.path.join(models_dir,'v1_y_rescaled_'+str(sex)+'.txt')\n",
    "np.savetxt(v1_y_te_rescaled_f,y_te_rescaled)\n",
    "\n",
    "\n",
    "# V1 plot the (adjusted) data points\n",
    "v1_plot = df_te['age'].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(v1_plot, y_te_rescaled, color='darkgreen', label='V1', alpha = 0.9)\n",
    "\n",
    "# plot the median of the dummy data\n",
    "plt.plot(xx, med, clr)\n",
    "\n",
    "# fill the gaps in between the centiles\n",
    "junk, pr_int25 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.25,0.75])\n",
    "junk, pr_int95 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.05,0.95])\n",
    "junk, pr_int99 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.01,0.99])\n",
    "plt.fill_between(xx, pr_int25[:,0], pr_int25[:,1], alpha = 0.1,color=clr)\n",
    "plt.fill_between(xx, pr_int95[:,0], pr_int95[:,1], alpha = 0.1,color=clr)\n",
    "plt.fill_between(xx, pr_int99[:,0], pr_int99[:,1], alpha = 0.1,color=clr)\n",
    "        \n",
    "# make the width of each centile proportional to the epistemic uncertainty\n",
    "junk, pr_int25l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.25,0.75])\n",
    "junk, pr_int95l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.05,0.95])\n",
    "junk, pr_int99l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.01,0.99])\n",
    "junk, pr_int25u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.25,0.75])\n",
    "junk, pr_int95u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.05,0.95])\n",
    "junk, pr_int99u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.01,0.99])    \n",
    "plt.fill_between(xx, pr_int25l[:,0], pr_int25u[:,0], alpha = 0.3,color=clr)\n",
    "plt.fill_between(xx, pr_int95l[:,0], pr_int95u[:,0], alpha = 0.3,color=clr)\n",
    "plt.fill_between(xx, pr_int99l[:,0], pr_int99u[:,0], alpha = 0.3,color=clr)\n",
    "plt.fill_between(xx, pr_int25l[:,1], pr_int25u[:,1], alpha = 0.3,color=clr)\n",
    "plt.fill_between(xx, pr_int95l[:,1], pr_int95u[:,1], alpha = 0.3,color=clr)\n",
    "plt.fill_between(xx, pr_int99l[:,1], pr_int99u[:,1], alpha = 0.3,color=clr)\n",
    "\n",
    "# plot actual centile lines\n",
    "plt.plot(xx, pr_int25[:,0],color=clr, linewidth=0.5)\n",
    "plt.plot(xx, pr_int25[:,1],color=clr, linewidth=0.5)\n",
    "plt.plot(xx, pr_int95[:,0],color=clr, linewidth=0.5)\n",
    "plt.plot(xx, pr_int95[:,1],color=clr, linewidth=0.5)\n",
    "plt.plot(xx, pr_int99[:,0],color=clr, linewidth=0.5)\n",
    "plt.plot(xx, pr_int99[:,1],color=clr, linewidth=0.5)\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel(idp) \n",
    "plt.title(idp)\n",
    "plt.xlim((10,60))\n",
    "plt.legend()\n",
    "#plt.savefig(os.path.join('centiles_' + str(sex)),  bbox_inches='tight')\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(images_dir,idp+'_'+str(sex)+'.png'))\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
