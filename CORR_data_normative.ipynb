{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as ss\n",
    "\n",
    "ext_scripts_dir = ('/home/barbora/Documents/Projects/Normative_Models/ESO/braincharts/scripts')\n",
    "os.chdir(ext_scripts_dir)\n",
    "\n",
    "from nm_utils import remove_bad_subjects, load_2d\n",
    "\n",
    "code_dir = ('/home/barbora/Documents/Projects/Normative_Models/ESO/code')\n",
    "os.chdir(code_dir)\n",
    "\n",
    "# importing custom functions\n",
    "import clinics_desc_functions as custom\n",
    "\n",
    "sns.set(rc={'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_models_for_analysis\n",
    "\n",
    "model_name, site_names, site_ids_tr, idp_ids = custom.pretrained_ini()\n",
    "\n",
    "# where things are\n",
    "main_dir = ('/home/barbora/Documents/Projects/Normative_Models/COINS')\n",
    "models_dir = ('/home/barbora/Documents/Projects/Normative_Models/COINS/models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "fsdata_dir = ('/home/barbora/Documents/Projects/Normative_Models/COINS/backup')\n",
    "pretrained_dir = ('/home/barbora/Documents/Projects/Normative_Models/ESO/braincharts/models/lifespan_57K_82sites')\n",
    "images_dir = os.path.join(models_dir,'img')\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "out_dir = models_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FS info\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_fs = pd.read_csv(os.path.join(fsdata_dir,'fit_external_long_thickness_1.txt'), sep=';')\n",
    "v1_fs.index = [i.split('.')[-1][2:] for i in v1_fs['id']]\n",
    "v1_fs = v1_fs.drop(columns= 'id')\n",
    "v1_fs.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_fs = pd.read_csv(os.path.join(fsdata_dir,'fit_external_long_thickness_2.txt'), sep=';')\n",
    "v2_fs.index = [i.split('.')[-1][2:] for i in v2_fs['id']]\n",
    "v2_fs = v2_fs.drop(columns= 'id')\n",
    "v2_fs.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicies acoss the two dataframes are in sync!\n"
     ]
    }
   ],
   "source": [
    "if sum(v1_fs.index == v2_fs.index) == v1_fs.shape[0]:\n",
    "    print('Indicies acoss the two dataframes are in sync!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load clinics\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_clin = pd.read_csv(os.path.join(fsdata_dir, 'CoRR_AggregatedPhenotypicData.csv'))\n",
    "pk = [str(i) for i in corr_clin['SUBID']]\n",
    "corr_clin.index = pk\n",
    "corr_clin.sort_index(inplace=True)\n",
    "\n",
    "corr_clin.rename(columns={'SEX':'sex', 'AGE_AT_SCAN_1':'age', 'SITE':'site'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete subjects that were not processed\n",
    "del_from_clin = list(set(corr_clin.index.unique()) - set(v1_fs.index))\n",
    "corr_clin = corr_clin.drop(index= del_from_clin)\n",
    "corr_clin = corr_clin[corr_clin['SESSION']=='Baseline']\n",
    "\n",
    "# relabel SEX to 0-females; 1-males\n",
    "corr_clin['sex'] = corr_clin['sex'].replace({'1': '0', '2':'1'})\n",
    "corr_clin['sex']= corr_clin['sex'].astype(int)\n",
    "\n",
    "# change age to number\n",
    "corr_clin['age'] = pd.to_numeric(corr_clin['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sitenum for distinct sites\n",
    "sites = corr_clin['site'].unique()\n",
    "df_sites = corr_clin.groupby('site').agg('nunique')\n",
    "df_sites['sitenum'] = range(1001,1001+len(sites))\n",
    "dict_sites = df_sites['sitenum'].to_dict()\n",
    "corr_clin['sitenum'] = corr_clin['site']\n",
    "corr_clin['sitenum'].replace(dict_sites, inplace=True)\n",
    "\n",
    "# Delete sites with less than 20 subjects\n",
    "sites_pivot = corr_clin.groupby('site').agg('count')['SUBID']\n",
    "sites_small = sites_pivot[sites_pivot<20].index\n",
    "\n",
    "corr_clin = corr_clin.drop(index=corr_clin.iloc[np.where(corr_clin['site'].isin(sites_small))[0]].index)\n",
    "\n",
    "# extract a list of unique site ids from the test set\n",
    "site_ids_te =  sorted(set(corr_clin['site'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete from v1_fs, v2_fs\n",
    "del_from_fs = list(set(v1_fs.index) - set(corr_clin.index.unique()))\n",
    "v1_fs = v1_fs.drop(index = del_from_fs)\n",
    "v2_fs = v2_fs.drop(index = del_from_fs)\n",
    "\n",
    "# add age and sex data to fs dataframes\n",
    "v1_fs = pd.concat([v1_fs,corr_clin[['sex', 'age', 'site', 'sitenum']]],axis=1,join='inner')\n",
    "v2_fs = pd.concat([v2_fs,corr_clin[['sex', 'age', 'site', 'sitenum']]],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Normative models**\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcntoolkit.normative import estimate, predict, evaluate\n",
    "from pcntoolkit.util.utils import compute_MSLL, create_design_matrix\n",
    "\n",
    "####\n",
    "# Getting a pretrained model\n",
    "# ###\n",
    "model_name, site_names, site_ids_tr, idp_ids = custom.pretrained_ini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split - split across sites, keep 30% as training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "index_split_ad = list()\n",
    "index_split_te = list()\n",
    "\n",
    "for i, isite in enumerate(site_ids_te):\n",
    "    site_spec_ind = corr_clin.index[(corr_clin['site']==isite)]\n",
    "    \n",
    "    if i == 0:\n",
    "        index_split_te, index_split_ad = train_test_split(site_spec_ind, test_size = 0.3, shuffle = False, random_state = 42)\n",
    "    else:\n",
    "        b, a = train_test_split(site_spec_ind, random_state = 42)\n",
    "        index_split_ad = index_split_ad.append(a)\n",
    "        index_split_te = index_split_te.append(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to change the visit and run twice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Configure covariates\n",
    "###\n",
    "# which data columns do we wish to use as covariates? \n",
    "cols_cov = ['age','sex']\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = -5 \n",
    "xmax = 110\n",
    "\n",
    "# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)\n",
    "outlier_thresh = 7\n",
    "\n",
    "# which visit to analyze?\n",
    "which_visit = 2\n",
    "\n",
    "# Pick the correct dataset for modelling\n",
    "if which_visit == 1:\n",
    "    df_ad = v1_fs.loc[index_split_ad]\n",
    "    df_te = v1_fs.loc[index_split_te]\n",
    "    df_ad.to_csv(os.path.join(models_dir,'V1','df_ad.csv'), sep=' ', index= True)\n",
    "    df_te.to_csv(os.path.join(models_dir,'V1','df_te.csv'), sep=' ', index= True)\n",
    "\n",
    "else:\n",
    "    df_ad = v2_fs.loc[index_split_ad]\n",
    "    df_te = v2_fs.loc[index_split_te]\n",
    "    df_ad.to_csv(os.path.join(models_dir,'V2','df_ad.csv'), sep=' ', index= True)\n",
    "    df_te.to_csv(os.path.join(models_dir,'V2','df_te.csv'), sep=' ', index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IDP 0 lh_G&S_frontomargin_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 1 lh_G&S_occipital_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 2 lh_G&S_paracentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 3 lh_G&S_subcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 4 lh_G&S_transv_frontopol_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 5 lh_G&S_cingul-Ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 6 lh_G&S_cingul-Mid-Ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 7 lh_G&S_cingul-Mid-Post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 8 lh_G_cingul-Post-dorsal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 9 lh_G_cingul-Post-ventral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 10 lh_G_cuneus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 11 lh_G_front_inf-Opercular_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 12 lh_G_front_inf-Orbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 13 lh_G_front_inf-Triangul_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 14 lh_G_front_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 15 lh_G_front_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 16 lh_G_Ins_lg&S_cent_ins_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 17 lh_G_insular_short_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 18 lh_G_occipital_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 19 lh_G_occipital_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 20 lh_G_oc-temp_lat-fusifor_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 21 lh_G_oc-temp_med-Lingual_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 22 lh_G_oc-temp_med-Parahip_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 23 lh_G_orbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 24 lh_G_pariet_inf-Angular_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 25 lh_G_pariet_inf-Supramar_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 26 lh_G_parietal_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 27 lh_G_postcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 28 lh_G_precentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 29 lh_G_precuneus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 30 lh_G_rectus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 31 lh_G_subcallosal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 32 lh_G_temp_sup-G_T_transv_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 33 lh_G_temp_sup-Lateral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 34 lh_G_temp_sup-Plan_polar_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 35 lh_G_temp_sup-Plan_tempo_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 36 lh_G_temporal_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 37 lh_G_temporal_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 38 lh_Lat_Fis-ant-Horizont_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 39 lh_Lat_Fis-ant-Vertical_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 40 lh_Lat_Fis-post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 41 lh_Pole_occipital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 42 lh_Pole_temporal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 43 lh_S_calcarine_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 44 lh_S_central_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 45 lh_S_cingul-Marginalis_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 46 lh_S_circular_insula_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 47 lh_S_circular_insula_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 48 lh_S_circular_insula_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 49 lh_S_collat_transv_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 50 lh_S_collat_transv_post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 51 lh_S_front_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 52 lh_S_front_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 53 lh_S_front_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 54 lh_S_interm_prim-Jensen_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 55 lh_S_intrapariet&P_trans_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 56 lh_S_oc_middle&Lunatus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 57 lh_S_oc_sup&transversal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 58 lh_S_occipital_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 59 lh_S_oc-temp_lat_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 60 lh_S_oc-temp_med&Lingual_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 61 lh_S_orbital_lateral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 62 lh_S_orbital_med-olfact_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 63 lh_S_orbital-H_Shaped_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 64 lh_S_parieto_occipital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 65 lh_S_pericallosal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 66 lh_S_postcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 67 lh_S_precentral-inf-part_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 68 lh_S_precentral-sup-part_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 69 lh_S_suborbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 70 lh_S_subparietal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 71 lh_S_temporal_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 72 lh_S_temporal_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 73 lh_S_temporal_transverse_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 74 rh_G&S_frontomargin_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 75 rh_G&S_occipital_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 76 rh_G&S_paracentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 77 rh_G&S_subcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 78 rh_G&S_transv_frontopol_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 79 rh_G&S_cingul-Ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 80 rh_G&S_cingul-Mid-Ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 81 rh_G&S_cingul-Mid-Post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 82 rh_G_cingul-Post-dorsal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 83 rh_G_cingul-Post-ventral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 84 rh_G_cuneus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 85 rh_G_front_inf-Opercular_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 86 rh_G_front_inf-Orbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 87 rh_G_front_inf-Triangul_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 88 rh_G_front_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 89 rh_G_front_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 90 rh_G_Ins_lg&S_cent_ins_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 91 rh_G_insular_short_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 92 rh_G_occipital_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 93 rh_G_occipital_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 94 rh_G_oc-temp_lat-fusifor_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 95 rh_G_oc-temp_med-Lingual_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 96 rh_G_oc-temp_med-Parahip_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 97 rh_G_orbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 98 rh_G_pariet_inf-Angular_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 99 rh_G_pariet_inf-Supramar_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 100 rh_G_parietal_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 101 rh_G_postcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 102 rh_G_precentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 103 rh_G_precuneus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 104 rh_G_rectus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 105 rh_G_subcallosal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 106 rh_G_temp_sup-G_T_transv_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 107 rh_G_temp_sup-Lateral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 108 rh_G_temp_sup-Plan_polar_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 109 rh_G_temp_sup-Plan_tempo_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 110 rh_G_temporal_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 111 rh_G_temporal_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 112 rh_Lat_Fis-ant-Horizont_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 113 rh_Lat_Fis-ant-Vertical_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 114 rh_Lat_Fis-post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 115 rh_Pole_occipital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 116 rh_Pole_temporal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 117 rh_S_calcarine_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 118 rh_S_central_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 119 rh_S_cingul-Marginalis_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 120 rh_S_circular_insula_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 121 rh_S_circular_insula_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 122 rh_S_circular_insula_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 123 rh_S_collat_transv_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 124 rh_S_collat_transv_post_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 125 rh_S_front_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 126 rh_S_front_middle_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 127 rh_S_front_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 128 rh_S_interm_prim-Jensen_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 129 rh_S_intrapariet&P_trans_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 130 rh_S_oc_middle&Lunatus_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 131 rh_S_oc_sup&transversal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 132 rh_S_occipital_ant_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 133 rh_S_oc-temp_lat_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 134 rh_S_oc-temp_med&Lingual_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 135 rh_S_orbital_lateral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 136 rh_S_orbital_med-olfact_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 137 rh_S_orbital-H_Shaped_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 138 rh_S_parieto_occipital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 139 rh_S_pericallosal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 140 rh_S_postcentral_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 141 rh_S_precentral-inf-part_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 142 rh_S_precentral-sup-part_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 143 rh_S_suborbital_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 144 rh_S_subparietal_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 145 rh_S_temporal_inf_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 146 rh_S_temporal_sup_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 147 rh_S_temporal_transverse_thickness :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 148 Left-Lateral-Ventricle :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 149 Left-Inf-Lat-Vent :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 150 Left-Cerebellum-White-Matter :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 151 Left-Cerebellum-Cortex :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 152 Left-Thalamus-Proper :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 153 Left-Caudate :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 154 Left-Putamen :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 155 Left-Pallidum :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 156 3rd-Ventricle :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 157 4th-Ventricle :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 158 Brain-Stem :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 159 Left-Hippocampus :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 160 Left-Amygdala :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 161 CSF :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 162 Left-Accumbens-area :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 163 Left-VentralDC :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 164 Left-vessel :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 165 Left-choroid-plexus :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 166 Right-Lateral-Ventricle :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 167 Right-Inf-Lat-Vent :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 168 Right-Cerebellum-White-Matter :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 169 Right-Cerebellum-Cortex :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 170 Right-Thalamus-Proper :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 171 Right-Caudate :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 172 Right-Putamen :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 173 Right-Pallidum :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 174 Right-Hippocampus :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 175 Right-Amygdala :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 176 Right-Accumbens-area :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 177 Right-VentralDC :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 178 Right-vessel :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 179 Right-choroid-plexus :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 180 SubCortGrayVol :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 181 TotalGrayVol :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 182 SupraTentorialVol :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 183 SupraTentorialVolNotVent :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n",
      "Running IDP 184 EstimatedTotalIntraCranialVol :\n",
      "Some sites missing from the training data. Adapting model\n",
      "Loading data ...\n",
      "Prediction by model  1 of 1\n",
      "Evaluating the model ...\n",
      "Evaluations Writing outputs ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "# Running the models\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "    idp_dir = os.path.join(out_dir, 'V'+str(which_visit), idp)\n",
    "    \n",
    "    os.makedirs(idp_dir, exist_ok=True)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract and save the response variables for the test set\n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    \n",
    "    # save the variables\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "        \n",
    "    # configure and save the design matrix\n",
    "    cov_file_te = os.path.join(idp_dir, 'cov_bspline_te.txt')\n",
    "    X_te = create_design_matrix(df_te[cols_cov], \n",
    "                                site_ids = df_te['site'],\n",
    "                                all_sites = site_ids_tr,\n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "    np.savetxt(cov_file_te, X_te)\n",
    "    \n",
    "    # check whether all sites in the test set are represented in the training set\n",
    "    if all(elem in site_ids_tr for elem in site_ids_te):\n",
    "        print('All sites are present in the training data')\n",
    "        \n",
    "        # just make predictions\n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg='blr', \n",
    "                                    respfile=resp_file_te, \n",
    "                                    model_path=os.path.join(idp_dir,'Models'))\n",
    "    else:\n",
    "        print('Some sites missing from the training data. Adapting model')\n",
    "        \n",
    "        # save the covariates for the adaptation data\n",
    "        X_ad = create_design_matrix(df_ad[cols_cov], \n",
    "                                    site_ids = df_ad['site'],\n",
    "                                    all_sites = site_ids_tr,\n",
    "                                    basis = 'bspline', \n",
    "                                    xmin = xmin, \n",
    "                                    xmax = xmax)\n",
    "        cov_file_ad = os.path.join(idp_dir, 'cov_bspline_ad.txt')          \n",
    "        np.savetxt(cov_file_ad, X_ad)\n",
    "        \n",
    "        # save the responses for the adaptation data\n",
    "        resp_file_ad = os.path.join(idp_dir, 'resp_ad.txt') \n",
    "        y_ad = df_ad[idp].to_numpy()\n",
    "        np.savetxt(resp_file_ad, y_ad)\n",
    "       \n",
    "        # save the site ids for the adaptation data\n",
    "        sitenum_file_ad = os.path.join(idp_dir, 'sitenum_ad.txt') \n",
    "        site_num_ad = df_ad['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_ad, site_num_ad)\n",
    "        \n",
    "        # save the site ids for the test data \n",
    "        sitenum_file_te = os.path.join(idp_dir, 'sitenum_te.txt')\n",
    "        site_num_te = df_te['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_te, site_num_te)\n",
    "         \n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg = 'blr', \n",
    "                                    respfile = resp_file_te, \n",
    "                                    model_path = os.path.join(pretrained_dir,idp,'Models'),\n",
    "                                    adaptrespfile = resp_file_ad,\n",
    "                                    adaptcovfile = cov_file_ad,\n",
    "                                    adaptvargroupfile = sitenum_file_ad,\n",
    "                                    testvargroupfile = sitenum_file_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the values across idps and visits and compare across sites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_z = custom.idp_concat(os.path.join(models_dir,'V1'), 'Z_predict.txt', idp_ids, 'CORR_V1_Z.csv', t_dir= models_dir)\n",
    "v2_z = custom.idp_concat(os.path.join(models_dir,'V2'), 'Z_predict.txt', idp_ids, 'CORR_V2_Z.csv', t_dir= models_dir)\n",
    "\n",
    "v1_z = pd.read_csv(v1_z, sep = ' ')\n",
    "v2_z = pd.read_csv(v2_z, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test-retest data\n",
    "v1_orig = pd.read_csv(os.path.join(models_dir, 'V1', 'df_te.csv'), sep=' ', index_col=0)\n",
    "v2_orig = pd.read_csv(os.path.join(models_dir, 'V2', 'df_te.csv'), sep=' ', index_col=0)\n",
    "\n",
    "# load the ESO controls data \n",
    "v1_cont = pd.read_csv(os.path.join('/home/barbora/Documents/Projects/Normative_Models/ESO/analyses/01_PANSS/data','v1_cont.txt'), sep=' ', index_col=0)\n",
    "v2_cont = pd.read_csv(os.path.join('/home/barbora/Documents/Projects/Normative_Models/ESO/analyses/01_PANSS/data','v2_cont.txt'), sep=' ', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_z.index = v1_orig.index\n",
    "v1_z['site'] = v1_orig['site']\n",
    "v1_z['age'] = v1_orig['age']\n",
    "v1_z['sex'] = v1_orig['sex']\n",
    "\n",
    "v2_z.index = v2_orig.index\n",
    "v2_z['site'] = v1_orig['site']\n",
    "v2_z['age'] = v1_orig['age']\n",
    "v2_z['sex'] = v1_orig['sex']\n",
    "\n",
    "# adding ESO data\n",
    "v1_z_all = pd.concat([v1_z[idp_ids+ cols_cov+['site']], v1_cont[idp_ids+ cols_cov+['site']]])\n",
    "v2_z_all = pd.concat([v2_z[idp_ids+ cols_cov+['site']], v2_cont[idp_ids+ cols_cov+['site']]])\n",
    "\n",
    "# diff\n",
    "diff = v2_z_all[idp_ids] - v1_z_all[idp_ids]\n",
    "diff['site'] = v1_z_all['site']\n",
    "diff['sex'] = v1_z_all['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting differences between visits across sites with respect to sex\n",
    "\n",
    "FM_colors = [\"coral\", \"darkseagreen\"]\n",
    "cp = sns.set_palette(sns.color_palette(FM_colors))\n",
    "\n",
    "\n",
    "for idp in idp_ids:\n",
    "    fig, ax = plt.subplots(2,1,figsize=(15,6))\n",
    "    ax[0] = sns.boxplot(x=\"site\", y=idp, data=diff, hue='sex', palette = cp, ax=ax[0])\n",
    "    ax[0].set(ylim=(-3, 3))\n",
    "#    ax[0].set_xticklabels(ax[0].get_xticklabels(),rotation = 30)\n",
    "    ax[0].axhline(0, linewidth = 3, color='#94B0DA')\n",
    "    ax[0].axvline(14.5, linewidth = 3, color='#94B0DA', linestyle='--')\n",
    "\n",
    "    ax[1] = sns.countplot(data=diff, x='site')\n",
    "    fig.suptitle(idp)\n",
    "\n",
    "    plt.savefig(os.path.join(models_dir, 'img',idp),  bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3951f2f4cd92dfb9d3e6d0b790d47ccf8f4798183357503ed7e741f4d780229a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('PCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
